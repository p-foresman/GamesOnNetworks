To Do:
-convert csv files to BLOBs in order to insert into database

Notes:
-look into static_scale_free vs barabasi_albert scale free networks. Which should i be using?
-should i be generating a new graph every iteration? or should each run in an averager use the same graph? (this way, the only randomness would come from the agents' choices)


For DB/DF:
DataFrames:
    -memory state, each row is an agent, each column is a single memory index for the given agent.
    -corresponding memory state tags dataframe?

    alternatively:
    -DB tables:
        -game types (always bargaining game for now): id, name, payoff_matrix (could just rebuild this based on name?), strategies (this is implicit in matrix)
        -graph types: id, type, (params? might want to have graph params here? could have params in a lower level table of graphs which points to graph types table?)
        -graphs: id, graph type, params (this table may be unncecessary)
        -simulations (sim specific things): id, game type (FK), graph type/graph (FK), params json, graph fadlist, 
        -agents: id, simulation (FK), agent json
-Second dataframe for 
-In database, columns include:
    -grouping ID (to find all simulation instances from a cohort of simulations)
    -random number generator state
    -simulation parameters (JSON?)
        -must be a simplified version to describe a single simulation case (no iterators)****
    -graph parameters (JSON?)
    -graph adjacency matrix (in DataFrame -> CSV)
    -agent JSON list?

    

For saving and restoring random number generator state:

julia> rand()
0.09028876420540066

julia> state = copy(Random.default_rng())
MersenneTwister(0xacbf17e36353b3a3a75764abc1e03e06, (0, 1002, 0, 2))

julia> rand()
0.5688115492566419

julia> copy!(Random.default_rng(), state)
MersenneTwister(0xacbf17e36353b3a3a75764abc1e03e06, (0, 1002, 0, 2))

julia> rand()
0.5688115492566419



Sampling distribution:
-The sampling distribution of the random variable "transition time" will be different for a sample size of
    1 agent, 10 agents (or some cluster), and the total population (say 100 agents).
    Could construct histograms/sampling distributions for each of these emergent layers (with many replications)
    and compare the results.



FOR DB QUERIES
-need to reproduce simulation components from DB
-need queries for various plotting/data-viewing stuff

-can pull from db and reconstruct one by one for an iteration of simulations, then push back in one by one when finished.
 - however, likely shouldnt use averager to store to database bc every averaged iteration will be stored. (although this would be good for analysis)

 -for tomorrow: remove agents from Game struct. this way, full struct can be saved to be reproduced (also doesnt have to be mutable)


-Games struct is kind of a mess. Need to somehow store many StructType global definitions for different Game{size, size} sizes for proper JSON3 functionality for each size
    -Might be able to eliminate StaticArrays now that payoff_matrix_size is in DB anyway?


-keeping strategies for now. could remove since theyre implicit.  



-change grouping_ids to floats and add 0.01 each time the simulation is continued (this gives 100 possible continuations. more than enough)

-could eliminate grouping_ids and create a meta-params db table containing averager, use_seed, random_seed
    -or could contain all sim-params without simulation-specific findings. This would allow for a large number of averaged simulations to be grouped together. maybe this could contain the grouping id?





Questions for Rajesh:
-do we want to restore the RNG state even if the random seed wasnt originally set? It probably doesnt matter, but this way would ensure a true continuation

-The sampling distribution of the random variable "transition time" will be different for a sample size of
    1 agent, 10 agents (or some cluster), and the total population (say 100 agents).
    Could construct histograms/sampling distributions for each of these emergent layers (with many replications)
    and compare the results.

-find percentage of agents transitioned over periods

-find optimal error rate. This would show the amount of randomness/risk is ideal to reach the global equilibrium the fastest

-add disturbances

-stochastic stability *******
    what is the interaction between the stochastic stability and the network structure

-noise induced phenomenon
-young's papers




-implement simulation_type column in simulations table along with init_state?




CHOICE TENDANCIES - based on
memory_length = 7: [0.25, 0.3888888888888889, 0.3611111111111111]
memory_length = 8: [0.2222222222222222, 0.4666666666666667, 0.3111111111111111]
memory_length = 9: [0.23636363636363636, 0.43636363636363634, 0.32727272727272727]
memory_length = 10: [0.21212121212121213, 0.4696969696969697, 0.3181818181818182]
memory_length = 11: [0.23076923076923078, 0.44871794871794873, 0.32051282051282054]
memory_length = 12: [0.21978021978021978, 0.4175824175824176, 0.3626373626373626]
memory_length = 13: [0.22857142857142856, 0.45714285714285713, 0.3142857142857143]
memory_length = 14: [0.24166666666666667, 0.43333333333333335, 0.325]
memory_length = 15: [0.22058823529411764, 0.4632352941176471, 0.3161764705882353]
memory_length = 16: [0.23529411764705882, 0.4444444444444444, 0.3202614379084967]
memory_length = 17: [0.21637426900584794, 0.4327485380116959, 0.3508771929824561]
memory_length = 18: [0.22631578947368422, 0.45789473684210524, 0.3157894736842105]
memory_length = 19: [0.21904761904761905, 0.4380952380952381, 0.34285714285714286]
memory_length = 20: [0.22077922077922077, 0.45021645021645024, 0.329004329004329]